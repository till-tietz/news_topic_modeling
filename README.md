# News Topic Modeling

## 1. Probelm Framing \& Goals

### 1.1 Problem Framing

Given the team's recent focus on recommender systems and the clear NLP / ML focus of this challenge I framed the problem with the following business case in mind.

- A small but high quality labeled data-set of product attributes and descriptive meta-data (in this case topics) exists
- The company needs to:
    - find a way to quickly and easily/cheaply scale this meta-data tagging to a vast unlabelled item catalog
    - find a way to efficiently run queries for similar itmes to enhance recommendation and ultimately drive higher engagement and basket value

### 1.2 Goals

The following goals follow naturally from the above problem framing:

- **tagging and reccommending**: build a single model that can both tag and recommend
- **cheap**: make this model lightweight and non-resource intensive to run (see specified environment constraints)
- **easy**: this workflow should be generic and easily extensible as resources or improved models become available

Given the requirements for the role I additionally chose to emphasize ML model deployment skills over
statistical / methodological sophistication. That is; I approached the build as if I were planning to
lay the groundworks for pushing the generated docker image to production via VertexAI.

## 2. Design Decisions

### 2.1 Methods

I decided to utilize transfer learning feeding a pretrained `word2vec` embedding of the texts through
a LSTM + Dense layer RNN architecture with a multi-class classification objective.

**Reasoning:**

- transfer learning / refining a pre-trained embedding:
    - small data-set >> learning embeddings from scratch is infeasible and pre-trained embeddings give a performance boost
    - `word2vec` strikes a performance to resource requirements balance between simple encodings that are fast and easy to compute but lack context and rich semnatic information (e.g. `tfidf`) and advanced methods like transfomers that are too resource intensive for this application (no GPU)
- LSTM + Dense layer RNN:
    - yields strong performance on classification taks
    - Dense layer prior to final layer serves as an embedding that has been refined w.r.t the training objective and can be used to compute fast cosine similarities for reccomendation and ranking

### 2.2 Architecture

- all code relevant to the Docker image is contained in the `src` dircetory
- within `src` `main.py` serves as an entry point for the Docker image >> this main method simply runs workflows
- `src/workflows` houses workflow functions that execute logic (in this case only one main workflow exists) but for larger production projects separate train, predict, evaluate workflows can be implemented here
- `workflows` utilize methods (functions) related to loading and transforming data, loading models + artifacts, pre-processing, training, prediction and evaluation defined in `src/lib`

I opted for the above modular approach that encapsulates all methods in functions as it easy to extend, refactor and re-use; easy to reason about and easy to de-bug in production.

**NOTE:**
- I added no data validation or cleaning functionality as classes were balanced and the data was very clean
- many functions in `src/lib` implement more functionality than is actually used in the workflows (e.g. utilizing different models version for prediction, changing directories etc.) because I approached laying the groundworks with the goal of productionalization in mind.

## 3. Reproduce Results

#### 1. install lfs and clone the repo
**NOTE:** cloning may take some time due to a large embedding file (in the tradeoff between run-time and memory I chose runtime over memory optimization)

``` bash
cd
sudo apt install git-lfs
git lfs install
git clone https://github.com/till-tietz/news_topic_modeling.git
```

#### 2. create a local output directory so output generated by the docker image is accessible to you
``` bash
cd
mkdir mydockeroutputs
```

#### 3. build the docker image
```bash
cd news_topic_modeling
docker build --no-cache -t news_topic_modeling .
```

#### 4. run the docker image
#### 4.1 you can run it without training a new model instance (faster as workflows default to a saved instance)

```bash
cd
docker run -v "$(pwd)/mydockeroutputs:/app/output" news_topic_modeling --train false
```

#### 4.2 or with training a new model instance (slower and not recommended)

```bash
cd
docker run -v "$(pwd)/mydockeroutputs:/app/output" news_topic_modeling --train true
```


Once the image as run the following files should by in the `mydockeroutputs` directory
- `model_performance.png`: image with classification report, confusion matrix and one vs rest ROC
- `top_k_search_matches.json`: a json file with each article from the test set and its top 3 matches as determined by cosine similarities on the refined embedding space
- `tsne_embedding.png`: a 2D mapping of the refined embedding space

## 4. Next Steps with more time

### 4.1 Methods:
- investigate miss-classified instances with shaply to gain a deeper understanding of richer / more complex topics not captured by the current labelling
- following from the above use clustering on refined embedding combined with a simple LLM instance called via langchain to extend and improve the topic labelling
- try transfomer models with GPU acceleration to improve predictive performance
- try simple averaged `word2vec` embedding and lightgbm tree embeddings for a super light-weight predictor + embedding model
- extend functionality to non training / test data e.g. add option to pass user input text to cosine similarity retrieval functions

### 4.2 Architecture:
- WRITE TESTS!!!
- write utility bash scripts for Docker build + deploy jobs
- add github actions automation
- structure repository with poetry for better versioning and dependency management
- combine separate functions into more abstract classes where appropriate
- refactor to maximize re-usability and extensibility
- make logging cleaner